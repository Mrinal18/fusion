<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.9.2" />
<title>fusion.architecture.dcgan.dcgan_autoencoder API documentation</title>
<meta name="description" content="" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>fusion.architecture.dcgan.dcgan_autoencoder</code></h1>
</header>
<section id="section-intro">
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">from .dcgan_encoder import DcganEncoder
from .dcgan_decoder import DcganDecoder

from typing import Tuple

import torch.nn as nn
from torch import Tensor

from fusion.architecture import ABaseArchitecture
from fusion.architecture.abasearchitecture import TActivation, TConv, TNorm


class DcganAutoEncoder(ABaseArchitecture):
    def __init__(self,
         dim_in: int,
         dim_h: int,
         dim_l: int,
         dim_cls=None,
         input_size: int = 32,
         input_dim: int = 2,
         conv_layer_class: TConv = nn.Conv2d,
         conv_t_layer_class: TConv = nn.ConvTranspose2d,
         norm_layer_class: TNorm = nn.BatchNorm2d,
         activation_class: TActivation = nn.LeakyReLU,
         weights_initialization_type: str = &#39;xavier_uniform&#39;,
     ):
        &#34;&#34;&#34;
        The DCGAN Autoencoder class
        Args:
            dim_in: The number of input channels
            dim_h: The number of feature channels for the first convolutional layer, the number of feature channels double with each next convolutional layer in the encoder
                          The number of feature channels are consecutively halved in the decoder starting with the first and the last layer has dim_h number of feature channels
            dim_l: The number of latent dimensions
            dim_cls: A list of scalars, where each number should correspond to the output width for one of the convolutional layers.
                            The information between latent variable z and the convolutional feature maps width widths in dim_cls are maximized.
                            If dim_cls=None, the information between z and none of the convolutional feature maps is maximized, default=None
            input_size: The input width and height of the image, default=32
            input_dim: The number of input dimensions, e.g. an image is 2-dimensional (input_dim=2) and a volume is 3-dimensional (input_dim=3), default=2
            conv_layer_class: The type of convolutional layer to use, default=nn.Conv2d
            conv_t_layer_class: The type of transposed convolutional layer to use, default=nn.ConvTranspose2d
            norm_layer_class: The type of normalization layer to use, default=nn.BatchNorm2d
            activation_class: The type of non-linear activation function to use, default=nn.LeakyReLU
            weights_initialization_type: The weight initialization type to use, default=&#39;xavier_uniform&#39;

        Returns:
            Class of DCGAN autoencoder model

        &#34;&#34;&#34;
        super().__init__()
        self._encoder = DcganEncoder(
            dim_in, dim_h, dim_l, dim_cls=dim_cls,
            input_size=input_size, conv_layer_class=conv_layer_class,
            norm_layer_class=norm_layer_class, activation_class=activation_class,
            weights_initialization_type=weights_initialization_type
        )
        self._decoder = DcganDecoder(
            dim_in, dim_h, dim_l, dim_cls=dim_cls,
            input_size=input_size, input_dim=input_dim,
            conv_layer_class=conv_t_layer_class,
            norm_layer_class=norm_layer_class,
            activation_class=activation_class,
            weights_initialization_type=weights_initialization_type
        )

    def forward(self, x: Tensor) -&gt; Tuple[Tuple, Tuple]:
        &#34;&#34;&#34;
        The forward method for the DCGAN autoencoder model
        Args:
            x: An input tensor
        Returns:
            z: The latent variable
            x_hat: A reconstruction of the original input tensor

        &#34;&#34;&#34;
        z, _ = self._encoder(x)
        x_hat, _ = self._decoder(z)
        return z, x_hat

    def init_weights(self):
        &#34;&#34;&#34;
        The weight initialization method for the encoder and decoder in the autoencoder
        Returns:
            Autoencoder with initialized weights

        &#34;&#34;&#34;
        self._encoder.init_weights()
        self._decoder.init_weights()</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="fusion.architecture.dcgan.dcgan_autoencoder.DcganAutoEncoder"><code class="flex name class">
<span>class <span class="ident">DcganAutoEncoder</span></span>
<span>(</span><span>dim_in: int, dim_h: int, dim_l: int, dim_cls=None, input_size: int = 32, input_dim: int = 2, conv_layer_class: Type[torch.nn.modules.conv._ConvNd] = torch.nn.modules.conv.Conv2d, conv_t_layer_class: Type[torch.nn.modules.conv._ConvNd] = torch.nn.modules.conv.ConvTranspose2d, norm_layer_class: Type[torch.nn.modules.batchnorm._BatchNorm] = torch.nn.modules.batchnorm.BatchNorm2d, activation_class: Type[torch.nn.modules.module.Module] = torch.nn.modules.activation.LeakyReLU, weights_initialization_type: str = 'xavier_uniform')</span>
</code></dt>
<dd>
<div class="desc"><p>Helper class that provides a standard way to create an ABC using
inheritance.</p>
<p>The DCGAN Autoencoder class</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>dim_in</code></strong></dt>
<dd>The number of input channels</dd>
<dt><strong><code>dim_h</code></strong></dt>
<dd>The number of feature channels for the first convolutional layer, the number of feature channels double with each next convolutional layer in the encoder
The number of feature channels are consecutively halved in the decoder starting with the first and the last layer has dim_h number of feature channels</dd>
<dt><strong><code>dim_l</code></strong></dt>
<dd>The number of latent dimensions</dd>
<dt><strong><code>dim_cls</code></strong></dt>
<dd>A list of scalars, where each number should correspond to the output width for one of the convolutional layers.
The information between latent variable z and the convolutional feature maps width widths in dim_cls are maximized.
If dim_cls=None, the information between z and none of the convolutional feature maps is maximized, default=None</dd>
<dt><strong><code>input_size</code></strong></dt>
<dd>The input width and height of the image, default=32</dd>
<dt><strong><code>input_dim</code></strong></dt>
<dd>The number of input dimensions, e.g. an image is 2-dimensional (input_dim=2) and a volume is 3-dimensional (input_dim=3), default=2</dd>
<dt><strong><code>conv_layer_class</code></strong></dt>
<dd>The type of convolutional layer to use, default=nn.Conv2d</dd>
<dt><strong><code>conv_t_layer_class</code></strong></dt>
<dd>The type of transposed convolutional layer to use, default=nn.ConvTranspose2d</dd>
<dt><strong><code>norm_layer_class</code></strong></dt>
<dd>The type of normalization layer to use, default=nn.BatchNorm2d</dd>
<dt><strong><code>activation_class</code></strong></dt>
<dd>The type of non-linear activation function to use, default=nn.LeakyReLU</dd>
<dt><strong><code>weights_initialization_type</code></strong></dt>
<dd>The weight initialization type to use, default='xavier_uniform'</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>Class of DCGAN autoencoder model</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class DcganAutoEncoder(ABaseArchitecture):
    def __init__(self,
         dim_in: int,
         dim_h: int,
         dim_l: int,
         dim_cls=None,
         input_size: int = 32,
         input_dim: int = 2,
         conv_layer_class: TConv = nn.Conv2d,
         conv_t_layer_class: TConv = nn.ConvTranspose2d,
         norm_layer_class: TNorm = nn.BatchNorm2d,
         activation_class: TActivation = nn.LeakyReLU,
         weights_initialization_type: str = &#39;xavier_uniform&#39;,
     ):
        &#34;&#34;&#34;
        The DCGAN Autoencoder class
        Args:
            dim_in: The number of input channels
            dim_h: The number of feature channels for the first convolutional layer, the number of feature channels double with each next convolutional layer in the encoder
                          The number of feature channels are consecutively halved in the decoder starting with the first and the last layer has dim_h number of feature channels
            dim_l: The number of latent dimensions
            dim_cls: A list of scalars, where each number should correspond to the output width for one of the convolutional layers.
                            The information between latent variable z and the convolutional feature maps width widths in dim_cls are maximized.
                            If dim_cls=None, the information between z and none of the convolutional feature maps is maximized, default=None
            input_size: The input width and height of the image, default=32
            input_dim: The number of input dimensions, e.g. an image is 2-dimensional (input_dim=2) and a volume is 3-dimensional (input_dim=3), default=2
            conv_layer_class: The type of convolutional layer to use, default=nn.Conv2d
            conv_t_layer_class: The type of transposed convolutional layer to use, default=nn.ConvTranspose2d
            norm_layer_class: The type of normalization layer to use, default=nn.BatchNorm2d
            activation_class: The type of non-linear activation function to use, default=nn.LeakyReLU
            weights_initialization_type: The weight initialization type to use, default=&#39;xavier_uniform&#39;

        Returns:
            Class of DCGAN autoencoder model

        &#34;&#34;&#34;
        super().__init__()
        self._encoder = DcganEncoder(
            dim_in, dim_h, dim_l, dim_cls=dim_cls,
            input_size=input_size, conv_layer_class=conv_layer_class,
            norm_layer_class=norm_layer_class, activation_class=activation_class,
            weights_initialization_type=weights_initialization_type
        )
        self._decoder = DcganDecoder(
            dim_in, dim_h, dim_l, dim_cls=dim_cls,
            input_size=input_size, input_dim=input_dim,
            conv_layer_class=conv_t_layer_class,
            norm_layer_class=norm_layer_class,
            activation_class=activation_class,
            weights_initialization_type=weights_initialization_type
        )

    def forward(self, x: Tensor) -&gt; Tuple[Tuple, Tuple]:
        &#34;&#34;&#34;
        The forward method for the DCGAN autoencoder model
        Args:
            x: An input tensor
        Returns:
            z: The latent variable
            x_hat: A reconstruction of the original input tensor

        &#34;&#34;&#34;
        z, _ = self._encoder(x)
        x_hat, _ = self._decoder(z)
        return z, x_hat

    def init_weights(self):
        &#34;&#34;&#34;
        The weight initialization method for the encoder and decoder in the autoencoder
        Returns:
            Autoencoder with initialized weights

        &#34;&#34;&#34;
        self._encoder.init_weights()
        self._decoder.init_weights()</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="fusion.architecture.abasearchitecture.ABaseArchitecture" href="../abasearchitecture.html#fusion.architecture.abasearchitecture.ABaseArchitecture">ABaseArchitecture</a></li>
<li>abc.ABC</li>
<li>torch.nn.modules.module.Module</li>
</ul>
<h3>Class variables</h3>
<dl>
<dt id="fusion.architecture.dcgan.dcgan_autoencoder.DcganAutoEncoder.dump_patches"><code class="name">var <span class="ident">dump_patches</span> : bool</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="fusion.architecture.dcgan.dcgan_autoencoder.DcganAutoEncoder.training"><code class="name">var <span class="ident">training</span> : bool</code></dt>
<dd>
<div class="desc"></div>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="fusion.architecture.dcgan.dcgan_autoencoder.DcganAutoEncoder.forward"><code class="name flex">
<span>def <span class="ident">forward</span></span>(<span>self, x: torch.Tensor) ‑> Tuple[Tuple, Tuple]</span>
</code></dt>
<dd>
<div class="desc"><p>The forward method for the DCGAN autoencoder model</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>x</code></strong></dt>
<dd>An input tensor</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>z</code></dt>
<dd>The latent variable</dd>
<dt><code>x_hat</code></dt>
<dd>A reconstruction of the original input tensor</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def forward(self, x: Tensor) -&gt; Tuple[Tuple, Tuple]:
    &#34;&#34;&#34;
    The forward method for the DCGAN autoencoder model
    Args:
        x: An input tensor
    Returns:
        z: The latent variable
        x_hat: A reconstruction of the original input tensor

    &#34;&#34;&#34;
    z, _ = self._encoder(x)
    x_hat, _ = self._decoder(z)
    return z, x_hat</code></pre>
</details>
</dd>
<dt id="fusion.architecture.dcgan.dcgan_autoencoder.DcganAutoEncoder.init_weights"><code class="name flex">
<span>def <span class="ident">init_weights</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>The weight initialization method for the encoder and decoder in the autoencoder</p>
<h2 id="returns">Returns</h2>
<p>Autoencoder with initialized weights</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def init_weights(self):
    &#34;&#34;&#34;
    The weight initialization method for the encoder and decoder in the autoencoder
    Returns:
        Autoencoder with initialized weights

    &#34;&#34;&#34;
    self._encoder.init_weights()
    self._decoder.init_weights()</code></pre>
</details>
</dd>
</dl>
<h3>Inherited members</h3>
<ul class="hlist">
<li><code><b><a title="fusion.architecture.abasearchitecture.ABaseArchitecture" href="../abasearchitecture.html#fusion.architecture.abasearchitecture.ABaseArchitecture">ABaseArchitecture</a></b></code>:
<ul class="hlist">
<li><code><a title="fusion.architecture.abasearchitecture.ABaseArchitecture.get_layers" href="../abasearchitecture.html#fusion.architecture.abasearchitecture.ABaseArchitecture.get_layers">get_layers</a></code></li>
</ul>
</li>
</ul>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="fusion.architecture.dcgan" href="index.html">fusion.architecture.dcgan</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="fusion.architecture.dcgan.dcgan_autoencoder.DcganAutoEncoder" href="#fusion.architecture.dcgan.dcgan_autoencoder.DcganAutoEncoder">DcganAutoEncoder</a></code></h4>
<ul class="">
<li><code><a title="fusion.architecture.dcgan.dcgan_autoencoder.DcganAutoEncoder.dump_patches" href="#fusion.architecture.dcgan.dcgan_autoencoder.DcganAutoEncoder.dump_patches">dump_patches</a></code></li>
<li><code><a title="fusion.architecture.dcgan.dcgan_autoencoder.DcganAutoEncoder.forward" href="#fusion.architecture.dcgan.dcgan_autoencoder.DcganAutoEncoder.forward">forward</a></code></li>
<li><code><a title="fusion.architecture.dcgan.dcgan_autoencoder.DcganAutoEncoder.init_weights" href="#fusion.architecture.dcgan.dcgan_autoencoder.DcganAutoEncoder.init_weights">init_weights</a></code></li>
<li><code><a title="fusion.architecture.dcgan.dcgan_autoencoder.DcganAutoEncoder.training" href="#fusion.architecture.dcgan.dcgan_autoencoder.DcganAutoEncoder.training">training</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc"><cite>pdoc</cite> 0.9.2</a>.</p>
</footer>
</body>
</html>