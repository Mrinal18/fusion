<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.9.2" />
<title>fusion.criterion.loss API documentation</title>
<meta name="description" content="" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>fusion.criterion.loss</code></h1>
</header>
<section id="section-intro">
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">from .abaseloss import ABaseLoss
from .pytorch_wrappers import CustomCrossEntropyLoss
from .pytorch_wrappers import BCEWithLogitsLoss
from .ae import AE
from .cr_cca import CR_CCA
from .rr_ae import RR_AE
from .dccae import DCCAE
from .multi_dim import SpatialMultiDim, VolumetricMultiDim


__all__ = [
    &#39;ABaseLoss&#39;,
    &#39;CustomCrossEntropyLoss&#39;,
    &#39;BCEWithLogitsLoss&#39;,
    &#39;AE&#39;,
    &#39;SpatialMultiDim&#39;,
    &#39;VolumetricMultiDim&#39;,
    &#39;RR_AE&#39;,
    &#39;CR_CCA&#39;,
    &#39;DCCAE&#39;
]</code></pre>
</details>
</section>
<section>
<h2 class="section-title" id="header-submodules">Sub-modules</h2>
<dl>
<dt><code class="name"><a title="fusion.criterion.loss.abaseloss" href="abaseloss.html">fusion.criterion.loss.abaseloss</a></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt><code class="name"><a title="fusion.criterion.loss.ae" href="ae.html">fusion.criterion.loss.ae</a></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt><code class="name"><a title="fusion.criterion.loss.cr_cca" href="cr_cca.html">fusion.criterion.loss.cr_cca</a></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt><code class="name"><a title="fusion.criterion.loss.dccae" href="dccae.html">fusion.criterion.loss.dccae</a></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt><code class="name"><a title="fusion.criterion.loss.dim" href="dim/index.html">fusion.criterion.loss.dim</a></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt><code class="name"><a title="fusion.criterion.loss.multi_dim" href="multi_dim.html">fusion.criterion.loss.multi_dim</a></code></dt>
<dd>
<div class="desc"><p>MIT License â€¦</p></div>
</dd>
<dt><code class="name"><a title="fusion.criterion.loss.pytorch_wrappers" href="pytorch_wrappers.html">fusion.criterion.loss.pytorch_wrappers</a></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt><code class="name"><a title="fusion.criterion.loss.rr_ae" href="rr_ae.html">fusion.criterion.loss.rr_ae</a></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt><code class="name"><a title="fusion.criterion.loss.tests" href="tests/index.html">fusion.criterion.loss.tests</a></code></dt>
<dd>
<div class="desc"></div>
</dd>
</dl>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="fusion.criterion.loss.ABaseLoss"><code class="flex name class">
<span>class <span class="ident">ABaseLoss</span></span>
</code></dt>
<dd>
<div class="desc"><p>Helper class that provides a standard way to create an ABC using
inheritance.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class ABaseLoss(abc.ABC, nn.Module):
    @abc.abstractmethod
    def __init__(self):
        super().__init__()

    def forward(
        self,
        preds: ModelOutput,
        target: Optional[Tensor] = None
    ) -&gt; Tuple[Optional[Tensor], Dict[str, Any]]:
        pass</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li>abc.ABC</li>
<li>torch.nn.modules.module.Module</li>
</ul>
<h3>Subclasses</h3>
<ul class="hlist">
<li><a title="fusion.criterion.loss.ae.AE" href="ae.html#fusion.criterion.loss.ae.AE">AE</a></li>
<li><a title="fusion.criterion.loss.cr_cca.CR_CCA" href="cr_cca.html#fusion.criterion.loss.cr_cca.CR_CCA">CR_CCA</a></li>
<li><a title="fusion.criterion.loss.dccae.DCCAE" href="dccae.html#fusion.criterion.loss.dccae.DCCAE">DCCAE</a></li>
<li><a title="fusion.criterion.loss.multi_dim.MultiDim" href="multi_dim.html#fusion.criterion.loss.multi_dim.MultiDim">MultiDim</a></li>
<li><a title="fusion.criterion.loss.pytorch_wrappers.BCEWithLogitsLoss" href="pytorch_wrappers.html#fusion.criterion.loss.pytorch_wrappers.BCEWithLogitsLoss">BCEWithLogitsLoss</a></li>
<li><a title="fusion.criterion.loss.pytorch_wrappers.CustomCrossEntropyLoss" href="pytorch_wrappers.html#fusion.criterion.loss.pytorch_wrappers.CustomCrossEntropyLoss">CustomCrossEntropyLoss</a></li>
<li><a title="fusion.criterion.loss.pytorch_wrappers.MSELoss" href="pytorch_wrappers.html#fusion.criterion.loss.pytorch_wrappers.MSELoss">MSELoss</a></li>
<li><a title="fusion.criterion.loss.rr_ae.RR_AE" href="rr_ae.html#fusion.criterion.loss.rr_ae.RR_AE">RR_AE</a></li>
<li><a title="fusion.criterion.misc.cca.canonical_correlation.CanonicalCorrelation" href="../misc/cca/canonical_correlation.html#fusion.criterion.misc.cca.canonical_correlation.CanonicalCorrelation">CanonicalCorrelation</a></li>
</ul>
<h3>Class variables</h3>
<dl>
<dt id="fusion.criterion.loss.ABaseLoss.dump_patches"><code class="name">var <span class="ident">dump_patches</span> :Â bool</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="fusion.criterion.loss.ABaseLoss.training"><code class="name">var <span class="ident">training</span> :Â bool</code></dt>
<dd>
<div class="desc"></div>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="fusion.criterion.loss.ABaseLoss.forward"><code class="name flex">
<span>def <span class="ident">forward</span></span>(<span>self, preds:Â <a title="fusion.model.misc.ModelOutput" href="../../model/misc/index.html#fusion.model.misc.ModelOutput">ModelOutput</a>, target:Â Union[torch.Tensor,Â NoneType]Â =Â None) â€‘>Â Tuple[Union[torch.Tensor,Â NoneType],Â Dict[str,Â Any]]</span>
</code></dt>
<dd>
<div class="desc"><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the :class:<code>Module</code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def forward(
    self,
    preds: ModelOutput,
    target: Optional[Tensor] = None
) -&gt; Tuple[Optional[Tensor], Dict[str, Any]]:
    pass</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="fusion.criterion.loss.AE"><code class="flex name class">
<span>class <span class="ident">AE</span></span>
<span>(</span><span>**kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>Helper class that provides a standard way to create an ABC using
inheritance.</p>
<p>kwargs:</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class AE(ABaseLoss):
    def __init__(self, **kwargs):
        &#34;&#34;&#34;

        kwargs:
        &#34;&#34;&#34;
        super().__init__()
        self._loss = nn.MSELoss(**kwargs)

    def forward(
        self,
        preds: ModelOutput,
        target: Optional[Tensor] = None
    ) -&gt; Tuple[Optional[Tensor], Dict[str, Any]]:
        &#34;&#34;&#34;

        preds:
        target:
        :return:
        &#34;&#34;&#34;
        total_loss = None
        raw_losses = {}
        for source_id in preds.z.keys():
            x_hat = preds.attrs[&#39;x_hat&#39;][source_id]
            x = preds.attrs[&#39;x&#39;][source_id]
            loss = self._loss(x_hat, x)
            total_loss = total_loss_summation(total_loss, loss)
            name = f&#39;AE_{source_id}&#39;
            raw_losses[name] = loss.item()
        return total_loss, raw_losses</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="fusion.criterion.loss.abaseloss.ABaseLoss" href="abaseloss.html#fusion.criterion.loss.abaseloss.ABaseLoss">ABaseLoss</a></li>
<li>abc.ABC</li>
<li>torch.nn.modules.module.Module</li>
</ul>
<h3>Class variables</h3>
<dl>
<dt id="fusion.criterion.loss.AE.dump_patches"><code class="name">var <span class="ident">dump_patches</span> :Â bool</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="fusion.criterion.loss.AE.training"><code class="name">var <span class="ident">training</span> :Â bool</code></dt>
<dd>
<div class="desc"></div>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="fusion.criterion.loss.AE.forward"><code class="name flex">
<span>def <span class="ident">forward</span></span>(<span>self, preds:Â <a title="fusion.model.misc.ModelOutput" href="../../model/misc/index.html#fusion.model.misc.ModelOutput">ModelOutput</a>, target:Â Union[torch.Tensor,Â NoneType]Â =Â None) â€‘>Â Tuple[Union[torch.Tensor,Â NoneType],Â Dict[str,Â Any]]</span>
</code></dt>
<dd>
<div class="desc"><p>preds:
target:
:return:</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def forward(
    self,
    preds: ModelOutput,
    target: Optional[Tensor] = None
) -&gt; Tuple[Optional[Tensor], Dict[str, Any]]:
    &#34;&#34;&#34;

    preds:
    target:
    :return:
    &#34;&#34;&#34;
    total_loss = None
    raw_losses = {}
    for source_id in preds.z.keys():
        x_hat = preds.attrs[&#39;x_hat&#39;][source_id]
        x = preds.attrs[&#39;x&#39;][source_id]
        loss = self._loss(x_hat, x)
        total_loss = total_loss_summation(total_loss, loss)
        name = f&#39;AE_{source_id}&#39;
        raw_losses[name] = loss.item()
    return total_loss, raw_losses</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="fusion.criterion.loss.BCEWithLogitsLoss"><code class="flex name class">
<span>class <span class="ident">BCEWithLogitsLoss</span></span>
<span>(</span><span>**kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>Helper class that provides a standard way to create an ABC using
inheritance.</p>
<p>Initilization of pytorch wrapper of class Binary Cross Entropy with
logits loss</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>kwargs</code></strong></dt>
<dd>parameters of Cross Entropy Loss</dd>
</dl>
<p>Return
Class of Binary Cross Entropy with logits loss</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class BCEWithLogitsLoss(ABaseLoss):
    def __init__(self, **kwargs):
        &#34;&#34;&#34;
        Initilization of pytorch wrapper of class Binary Cross Entropy with
         logits loss
        Args:
            kwargs: parameters of Cross Entropy Loss
        Return
            Class of Binary Cross Entropy with logits loss
        &#34;&#34;&#34;
        super().__init__()
        self._loss = nn.BCEWithLogitsLoss(**kwargs)

    def forward(
        self,
        preds: Tensor,
        target: Optional[Tensor] = None
    ) -&gt; Tuple[Optional[Tensor], Dict[str, Any]]:
        &#34;&#34;&#34;
        Forward method of class Binary Cross Entropy with
         logits loss
        Args:
            preds: input tensor
            target: target tensor

        Return:
             Class of Binary Cross Entropy with logits loss
             between input and target tensor
        &#34;&#34;&#34;
        assert target is not None
        total_loss = None
        raw_losses = {}
        for source_id, z in preds.z.items():
            loss = self._loss(z.squeeze(1), target)
            total_loss = total_loss_summation(total_loss, loss)
            raw_losses[f&#34;CE{source_id}&#34;] = loss
        return total_loss, raw_losses</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="fusion.criterion.loss.abaseloss.ABaseLoss" href="abaseloss.html#fusion.criterion.loss.abaseloss.ABaseLoss">ABaseLoss</a></li>
<li>abc.ABC</li>
<li>torch.nn.modules.module.Module</li>
</ul>
<h3>Class variables</h3>
<dl>
<dt id="fusion.criterion.loss.BCEWithLogitsLoss.dump_patches"><code class="name">var <span class="ident">dump_patches</span> :Â bool</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="fusion.criterion.loss.BCEWithLogitsLoss.training"><code class="name">var <span class="ident">training</span> :Â bool</code></dt>
<dd>
<div class="desc"></div>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="fusion.criterion.loss.BCEWithLogitsLoss.forward"><code class="name flex">
<span>def <span class="ident">forward</span></span>(<span>self, preds:Â torch.Tensor, target:Â Union[torch.Tensor,Â NoneType]Â =Â None) â€‘>Â Tuple[Union[torch.Tensor,Â NoneType],Â Dict[str,Â Any]]</span>
</code></dt>
<dd>
<div class="desc"><p>Forward method of class Binary Cross Entropy with
logits loss</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>preds</code></strong></dt>
<dd>input tensor</dd>
<dt><strong><code>target</code></strong></dt>
<dd>target tensor</dd>
</dl>
<h2 id="return">Return</h2>
<p>Class of Binary Cross Entropy with logits loss
between input and target tensor</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def forward(
    self,
    preds: Tensor,
    target: Optional[Tensor] = None
) -&gt; Tuple[Optional[Tensor], Dict[str, Any]]:
    &#34;&#34;&#34;
    Forward method of class Binary Cross Entropy with
     logits loss
    Args:
        preds: input tensor
        target: target tensor

    Return:
         Class of Binary Cross Entropy with logits loss
         between input and target tensor
    &#34;&#34;&#34;
    assert target is not None
    total_loss = None
    raw_losses = {}
    for source_id, z in preds.z.items():
        loss = self._loss(z.squeeze(1), target)
        total_loss = total_loss_summation(total_loss, loss)
        raw_losses[f&#34;CE{source_id}&#34;] = loss
    return total_loss, raw_losses</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="fusion.criterion.loss.CR_CCA"><code class="flex name class">
<span>class <span class="ident">CR_CCA</span></span>
<span>(</span><span>dim_cls:Â List[int], estimator_setting:Â <a title="fusion.utils.Setting" href="../../utils/index.html#fusion.utils.Setting">Setting</a>, cca_args:Â Dict[str,Â Any]Â =Â {}, input_dim:Â intÂ =Â 2)</span>
</code></dt>
<dd>
<div class="desc"><p>Helper class that provides a standard way to create an ABC using
inheritance.</p>
<p>Implementation of the CR-CCA loss</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>dim_cls</code></strong></dt>
<dd>A list of scalars, where each number should correspond to the output width for one of the convolutional layers.
The information between latent variable z and the convolutional feature maps width widths in dim_cls are maximized.</dd>
<dt><strong><code>estimator_setting</code></strong></dt>
<dd>Setting for Mutual Information estimator. See ABaseMIEstimator for details.</dd>
<dt><strong><code>cca_args</code></strong></dt>
<dd>See CanonicalCorrelation</dd>
<dt><strong><code>input_dim</code></strong></dt>
<dd>The number of input dimensions, e.g. an image is 2-dimensional (input_dim=2) and a volume is 3-dimensional (input_dim=3), default=2</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>Instance of CR_CCA</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class CR_CCA(ABaseLoss):
    def __init__(
        self,
        dim_cls: List[int],
        estimator_setting: Setting,
        cca_args: Dict[str, Any] = {},
        input_dim: int = 2,
    ):
        # ToDo: Add references to CanonicalCorrelation
        &#34;&#34;&#34;
        Implementation of the CR-CCA loss

        Args:
            dim_cls: A list of scalars, where each number should correspond to the output width for one of the convolutional layers.
                            The information between latent variable z and the convolutional feature maps width widths in dim_cls are maximized.
            estimator_setting: Setting for Mutual Information estimator. See ABaseMIEstimator for details.
            cca_args: See CanonicalCorrelation
            input_dim: The number of input dimensions, e.g. an image is 2-dimensional (input_dim=2) and a volume is 3-dimensional (input_dim=3), default=2
        Returns:
            Instance of CR_CCA
        &#34;&#34;&#34;
        super().__init__()
        assert len(dim_cls) &gt; 0, &#39;CR requires at leas one convolutional feature size&#39;
        self._cr_loss = choose_multi_dim(input_dim)(
            dim_cls,
            estimator_setting=estimator_setting,
            modes=[CR_MODE],
            weights=[1.]
        )
        self._cca_loss = CanonicalCorrelation(**cca_args)

    def forward(
        self,
        preds: ModelOutput,
        target: Optional[Tensor] = None
    ) -&gt; Tuple[Optional[Tensor], Dict[str, Any]]:
        &#34;&#34;&#34;
        Forward pass for the loss.

        Args:
            preds: Model output
            target: Targets, however, loss do no use them.
        Returns:
            total_loss: Total loss
            raw_losses: Dictionary for logging with all the computed losses
        &#34;&#34;&#34;
        total_loss = None
        raw_losses = {}
        loss, cr_raw = self._cr_loss(preds)
        raw_losses.update(cr_raw)
        total_loss = total_loss_summation(total_loss, loss)
        loss, cca_raw = self._cca_loss(preds)
        raw_losses.update(cca_raw)
        total_loss = total_loss_summation(total_loss, loss)
        return total_loss, raw_losses</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="fusion.criterion.loss.abaseloss.ABaseLoss" href="abaseloss.html#fusion.criterion.loss.abaseloss.ABaseLoss">ABaseLoss</a></li>
<li>abc.ABC</li>
<li>torch.nn.modules.module.Module</li>
</ul>
<h3>Class variables</h3>
<dl>
<dt id="fusion.criterion.loss.CR_CCA.dump_patches"><code class="name">var <span class="ident">dump_patches</span> :Â bool</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="fusion.criterion.loss.CR_CCA.training"><code class="name">var <span class="ident">training</span> :Â bool</code></dt>
<dd>
<div class="desc"></div>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="fusion.criterion.loss.CR_CCA.forward"><code class="name flex">
<span>def <span class="ident">forward</span></span>(<span>self, preds:Â <a title="fusion.model.misc.ModelOutput" href="../../model/misc/index.html#fusion.model.misc.ModelOutput">ModelOutput</a>, target:Â Union[torch.Tensor,Â NoneType]Â =Â None) â€‘>Â Tuple[Union[torch.Tensor,Â NoneType],Â Dict[str,Â Any]]</span>
</code></dt>
<dd>
<div class="desc"><p>Forward pass for the loss.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>preds</code></strong></dt>
<dd>Model output</dd>
<dt><strong><code>target</code></strong></dt>
<dd>Targets, however, loss do no use them.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>total_loss</code></dt>
<dd>Total loss</dd>
<dt><code>raw_losses</code></dt>
<dd>Dictionary for logging with all the computed losses</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def forward(
    self,
    preds: ModelOutput,
    target: Optional[Tensor] = None
) -&gt; Tuple[Optional[Tensor], Dict[str, Any]]:
    &#34;&#34;&#34;
    Forward pass for the loss.

    Args:
        preds: Model output
        target: Targets, however, loss do no use them.
    Returns:
        total_loss: Total loss
        raw_losses: Dictionary for logging with all the computed losses
    &#34;&#34;&#34;
    total_loss = None
    raw_losses = {}
    loss, cr_raw = self._cr_loss(preds)
    raw_losses.update(cr_raw)
    total_loss = total_loss_summation(total_loss, loss)
    loss, cca_raw = self._cca_loss(preds)
    raw_losses.update(cca_raw)
    total_loss = total_loss_summation(total_loss, loss)
    return total_loss, raw_losses</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="fusion.criterion.loss.CustomCrossEntropyLoss"><code class="flex name class">
<span>class <span class="ident">CustomCrossEntropyLoss</span></span>
<span>(</span><span>**kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>Helper class that provides a standard way to create an ABC using
inheritance.</p>
<p>Initilization of pytorch wrapper of class Cross Entropy Loss</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>kwargs</code></strong></dt>
<dd>parameters of Cross Entropy Loss</dd>
</dl>
<p>Return
Class of Cross Entropy Loss</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class CustomCrossEntropyLoss(ABaseLoss):
    def __init__(self, **kwargs):
        &#34;&#34;&#34;
        Initilization of pytorch wrapper of class Cross Entropy Loss
        Args:
            kwargs: parameters of Cross Entropy Loss
        Return
            Class of Cross Entropy Loss
        &#34;&#34;&#34;
        super().__init__()
        self._loss = nn.CrossEntropyLoss(**kwargs)

    def forward(
        self,
        preds: ModelOutput,
        target: Optional[Tensor] = None
    ) -&gt; Tuple[Optional[Tensor], Dict[str, Any]]:
        &#34;&#34;&#34;
        Forward method of class Cross Entropy Loss
        Args:
            preds: input model&#39;s output
            target: target tensor

        Return:
            Cross Entropy Loss between input and target tensor
        &#34;&#34;&#34;
        total_loss = None
        raw_losses = {}
        for source_id, z in preds.z.items():
            loss = self._loss(z, target)
            total_loss = total_loss_summation(total_loss, loss)
            raw_losses[f&#34;CE{source_id}&#34;] = loss
        return total_loss, raw_losses</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="fusion.criterion.loss.abaseloss.ABaseLoss" href="abaseloss.html#fusion.criterion.loss.abaseloss.ABaseLoss">ABaseLoss</a></li>
<li>abc.ABC</li>
<li>torch.nn.modules.module.Module</li>
</ul>
<h3>Class variables</h3>
<dl>
<dt id="fusion.criterion.loss.CustomCrossEntropyLoss.dump_patches"><code class="name">var <span class="ident">dump_patches</span> :Â bool</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="fusion.criterion.loss.CustomCrossEntropyLoss.training"><code class="name">var <span class="ident">training</span> :Â bool</code></dt>
<dd>
<div class="desc"></div>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="fusion.criterion.loss.CustomCrossEntropyLoss.forward"><code class="name flex">
<span>def <span class="ident">forward</span></span>(<span>self, preds:Â <a title="fusion.model.misc.ModelOutput" href="../../model/misc/index.html#fusion.model.misc.ModelOutput">ModelOutput</a>, target:Â Union[torch.Tensor,Â NoneType]Â =Â None) â€‘>Â Tuple[Union[torch.Tensor,Â NoneType],Â Dict[str,Â Any]]</span>
</code></dt>
<dd>
<div class="desc"><p>Forward method of class Cross Entropy Loss</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>preds</code></strong></dt>
<dd>input model's output</dd>
<dt><strong><code>target</code></strong></dt>
<dd>target tensor</dd>
</dl>
<h2 id="return">Return</h2>
<p>Cross Entropy Loss between input and target tensor</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def forward(
    self,
    preds: ModelOutput,
    target: Optional[Tensor] = None
) -&gt; Tuple[Optional[Tensor], Dict[str, Any]]:
    &#34;&#34;&#34;
    Forward method of class Cross Entropy Loss
    Args:
        preds: input model&#39;s output
        target: target tensor

    Return:
        Cross Entropy Loss between input and target tensor
    &#34;&#34;&#34;
    total_loss = None
    raw_losses = {}
    for source_id, z in preds.z.items():
        loss = self._loss(z, target)
        total_loss = total_loss_summation(total_loss, loss)
        raw_losses[f&#34;CE{source_id}&#34;] = loss
    return total_loss, raw_losses</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="fusion.criterion.loss.DCCAE"><code class="flex name class">
<span>class <span class="ident">DCCAE</span></span>
<span>(</span><span>cca_args:Â Dict[str,Â Any]Â =Â {})</span>
</code></dt>
<dd>
<div class="desc"><p>Helper class that provides a standard way to create an ABC using
inheritance.</p>
<p>Implementation of the DCCAE loss</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>cca_args</code></strong></dt>
<dd>See CanonicalCorrelation</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>Instance of DCCAE</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class DCCAE(ABaseLoss):
    def __init__(
        self,
        cca_args: Dict[str, Any] = {},
    ):
        # ToDo: Add references to CanonicalCorrelation
        &#34;&#34;&#34;
        Implementation of the DCCAE loss

        Args:
            cca_args: See CanonicalCorrelation
        Returns:
            Instance of DCCAE
        &#34;&#34;&#34;
        super().__init__()
        self._ae_loss = AE()
        self._cca_loss = CanonicalCorrelation(**cca_args)

    def forward(
        self,
        preds: ModelOutput,
        target: Optional[Tensor] = None
    ) -&gt; Tuple[Optional[Tensor], Dict[str, Any]]:
        &#34;&#34;&#34;
        Forward pass for the loss.

        Args:
            preds: Model output
            target: Targets, however, loss do no use them.
        Returns:
            total_loss: Total loss
            raw_losses: Dictionary for logging with all the computed losses
        &#34;&#34;&#34;
        total_loss = None
        raw_losses = {}
        loss, ae_raw = self._ae_loss(preds)
        raw_losses.update(ae_raw)
        total_loss = total_loss_summation(total_loss, loss)
        loss, cca_raw = self._cca_loss(preds)
        raw_losses.update(cca_raw)
        total_loss = total_loss_summation(total_loss, loss)
        return total_loss, raw_losses</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="fusion.criterion.loss.abaseloss.ABaseLoss" href="abaseloss.html#fusion.criterion.loss.abaseloss.ABaseLoss">ABaseLoss</a></li>
<li>abc.ABC</li>
<li>torch.nn.modules.module.Module</li>
</ul>
<h3>Class variables</h3>
<dl>
<dt id="fusion.criterion.loss.DCCAE.dump_patches"><code class="name">var <span class="ident">dump_patches</span> :Â bool</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="fusion.criterion.loss.DCCAE.training"><code class="name">var <span class="ident">training</span> :Â bool</code></dt>
<dd>
<div class="desc"></div>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="fusion.criterion.loss.DCCAE.forward"><code class="name flex">
<span>def <span class="ident">forward</span></span>(<span>self, preds:Â <a title="fusion.model.misc.ModelOutput" href="../../model/misc/index.html#fusion.model.misc.ModelOutput">ModelOutput</a>, target:Â Union[torch.Tensor,Â NoneType]Â =Â None) â€‘>Â Tuple[Union[torch.Tensor,Â NoneType],Â Dict[str,Â Any]]</span>
</code></dt>
<dd>
<div class="desc"><p>Forward pass for the loss.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>preds</code></strong></dt>
<dd>Model output</dd>
<dt><strong><code>target</code></strong></dt>
<dd>Targets, however, loss do no use them.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>total_loss</code></dt>
<dd>Total loss</dd>
<dt><code>raw_losses</code></dt>
<dd>Dictionary for logging with all the computed losses</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def forward(
    self,
    preds: ModelOutput,
    target: Optional[Tensor] = None
) -&gt; Tuple[Optional[Tensor], Dict[str, Any]]:
    &#34;&#34;&#34;
    Forward pass for the loss.

    Args:
        preds: Model output
        target: Targets, however, loss do no use them.
    Returns:
        total_loss: Total loss
        raw_losses: Dictionary for logging with all the computed losses
    &#34;&#34;&#34;
    total_loss = None
    raw_losses = {}
    loss, ae_raw = self._ae_loss(preds)
    raw_losses.update(ae_raw)
    total_loss = total_loss_summation(total_loss, loss)
    loss, cca_raw = self._cca_loss(preds)
    raw_losses.update(cca_raw)
    total_loss = total_loss_summation(total_loss, loss)
    return total_loss, raw_losses</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="fusion.criterion.loss.RR_AE"><code class="flex name class">
<span>class <span class="ident">RR_AE</span></span>
<span>(</span><span>estimator_setting:Â <a title="fusion.utils.Setting" href="../../utils/index.html#fusion.utils.Setting">Setting</a>)</span>
</code></dt>
<dd>
<div class="desc"><p>Helper class that provides a standard way to create an ABC using
inheritance.</p>
<p>Implementation of the RR-AE loss</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>estimator_setting</code></strong></dt>
<dd>Setting for Mutual Information estimator. See ABaseMIEstimator for details.</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>Instance of RR_AE</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class RR_AE(ABaseLoss):
    def __init__(
        self,
        estimator_setting: Setting,
    ):
        # ToDo: Add references to ABaseMIEstimator
        &#34;&#34;&#34;
        Implementation of the RR-AE loss

        Args:
            estimator_setting: Setting for Mutual Information estimator. See ABaseMIEstimator for details.
        Returns:
            Instance of RR_AE
        &#34;&#34;&#34;
        super().__init__()
        self._ae_loss = AE()
        self._rr_loss = MultiDim(
            dim_cls=[],
            estimator_setting=estimator_setting,
            modes=[RR_MODE],
            weights=[1.]
        )

    def forward(
        self,
        preds: ModelOutput,
        target: Optional[Tensor] = None
    ) -&gt; Tuple[Optional[Tensor], Dict[str, Any]]:
        &#34;&#34;&#34;
        Forward pass for the loss.

        Args:
            preds: Model output
            target: Targets, however, loss do no use them.
        Returns:
            total_loss: Total loss
            raw_losses: Dictionary for logging with all the computed losses
        &#34;&#34;&#34;
        total_loss = None
        raw_losses = {}
        loss, ae_raw = self._ae_loss(preds)
        raw_losses.update(ae_raw)
        total_loss = total_loss_summation(total_loss, loss)
        loss, rr_raw = self._rr_loss(preds)
        raw_losses.update(rr_raw)
        total_loss = total_loss_summation(total_loss, loss)
        return total_loss, raw_losses</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="fusion.criterion.loss.abaseloss.ABaseLoss" href="abaseloss.html#fusion.criterion.loss.abaseloss.ABaseLoss">ABaseLoss</a></li>
<li>abc.ABC</li>
<li>torch.nn.modules.module.Module</li>
</ul>
<h3>Class variables</h3>
<dl>
<dt id="fusion.criterion.loss.RR_AE.dump_patches"><code class="name">var <span class="ident">dump_patches</span> :Â bool</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="fusion.criterion.loss.RR_AE.training"><code class="name">var <span class="ident">training</span> :Â bool</code></dt>
<dd>
<div class="desc"></div>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="fusion.criterion.loss.RR_AE.forward"><code class="name flex">
<span>def <span class="ident">forward</span></span>(<span>self, preds:Â <a title="fusion.model.misc.ModelOutput" href="../../model/misc/index.html#fusion.model.misc.ModelOutput">ModelOutput</a>, target:Â Union[torch.Tensor,Â NoneType]Â =Â None) â€‘>Â Tuple[Union[torch.Tensor,Â NoneType],Â Dict[str,Â Any]]</span>
</code></dt>
<dd>
<div class="desc"><p>Forward pass for the loss.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>preds</code></strong></dt>
<dd>Model output</dd>
<dt><strong><code>target</code></strong></dt>
<dd>Targets, however, loss do no use them.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>total_loss</code></dt>
<dd>Total loss</dd>
<dt><code>raw_losses</code></dt>
<dd>Dictionary for logging with all the computed losses</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def forward(
    self,
    preds: ModelOutput,
    target: Optional[Tensor] = None
) -&gt; Tuple[Optional[Tensor], Dict[str, Any]]:
    &#34;&#34;&#34;
    Forward pass for the loss.

    Args:
        preds: Model output
        target: Targets, however, loss do no use them.
    Returns:
        total_loss: Total loss
        raw_losses: Dictionary for logging with all the computed losses
    &#34;&#34;&#34;
    total_loss = None
    raw_losses = {}
    loss, ae_raw = self._ae_loss(preds)
    raw_losses.update(ae_raw)
    total_loss = total_loss_summation(total_loss, loss)
    loss, rr_raw = self._rr_loss(preds)
    raw_losses.update(rr_raw)
    total_loss = total_loss_summation(total_loss, loss)
    return total_loss, raw_losses</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="fusion.criterion.loss.SpatialMultiDim"><code class="flex name class">
<span>class <span class="ident">SpatialMultiDim</span></span>
<span>(</span><span>dim_cls:Â List[int], estimator_setting:Â <a title="fusion.utils.Setting" href="../../utils/index.html#fusion.utils.Setting">Setting</a>, modes:Â List[str]Â =Â ['CR', 'XX', 'CC', 'RR'], weights:Â List[float]Â =Â [1.0, 1.0, 1.0, 1.0])</span>
</code></dt>
<dd>
<div class="desc"><p>Helper class that provides a standard way to create an ABC using
inheritance.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class SpatialMultiDim(MultiDim):
    def _create_masks(self) -&gt; Dict[int, nn.parameter.Parameter]:
        masks = {}
        for dim_cl in self._dim_cls:
            mask = np.zeros((dim_cl, dim_cl, 1, dim_cl, dim_cl))
            for i in range(dim_cl):
                for j in range(dim_cl):
                    mask[i, j, 0, i, j] = 1
            mask = torch.BoolTensor(mask)
            mask = mask.reshape(-1, 1, dim_cl, dim_cl)
            masks[dim_cl] = nn.Parameter(mask, requires_grad=False)
            if torch.cuda.is_available():
                masks[dim_cl].cuda()
        return masks</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="fusion.criterion.loss.multi_dim.MultiDim" href="multi_dim.html#fusion.criterion.loss.multi_dim.MultiDim">MultiDim</a></li>
<li><a title="fusion.criterion.loss.abaseloss.ABaseLoss" href="abaseloss.html#fusion.criterion.loss.abaseloss.ABaseLoss">ABaseLoss</a></li>
<li>abc.ABC</li>
<li>torch.nn.modules.module.Module</li>
</ul>
<h3>Class variables</h3>
<dl>
<dt id="fusion.criterion.loss.SpatialMultiDim.dump_patches"><code class="name">var <span class="ident">dump_patches</span> :Â bool</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="fusion.criterion.loss.SpatialMultiDim.training"><code class="name">var <span class="ident">training</span> :Â bool</code></dt>
<dd>
<div class="desc"></div>
</dd>
</dl>
<h3>Inherited members</h3>
<ul class="hlist">
<li><code><b><a title="fusion.criterion.loss.multi_dim.MultiDim" href="multi_dim.html#fusion.criterion.loss.multi_dim.MultiDim">MultiDim</a></b></code>:
<ul class="hlist">
<li><code><a title="fusion.criterion.loss.multi_dim.MultiDim.forward" href="abaseloss.html#fusion.criterion.loss.abaseloss.ABaseLoss.forward">forward</a></code></li>
</ul>
</li>
</ul>
</dd>
<dt id="fusion.criterion.loss.VolumetricMultiDim"><code class="flex name class">
<span>class <span class="ident">VolumetricMultiDim</span></span>
<span>(</span><span>dim_cls:Â List[int], estimator_setting:Â <a title="fusion.utils.Setting" href="../../utils/index.html#fusion.utils.Setting">Setting</a>, modes:Â List[str]Â =Â ['CR', 'XX', 'CC', 'RR'], weights:Â List[float]Â =Â [1.0, 1.0, 1.0, 1.0])</span>
</code></dt>
<dd>
<div class="desc"><p>Helper class that provides a standard way to create an ABC using
inheritance.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class VolumetricMultiDim(MultiDim):
    def _create_masks(self) -&gt; Dict[int, nn.parameter.Parameter]:
        masks = {}
        for dim_cl in self._dim_cls:
            mask = torch.zeros((dim_cl, dim_cl, dim_cl, 1, dim_cl, dim_cl, dim_cl))
            for i in range(dim_cl):
                for j in range(dim_cl):
                    for k in range(dim_cl):
                        mask[i, j, k, 0, i, j, k] = 1
            mask = torch.BoolTensor(mask)
            mask = mask.reshape(-1, 1, dim_cl, dim_cl, dim_cl)
            masks[dim_cl] = nn.Parameter(mask, requires_grad=False)
        return masks</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="fusion.criterion.loss.multi_dim.MultiDim" href="multi_dim.html#fusion.criterion.loss.multi_dim.MultiDim">MultiDim</a></li>
<li><a title="fusion.criterion.loss.abaseloss.ABaseLoss" href="abaseloss.html#fusion.criterion.loss.abaseloss.ABaseLoss">ABaseLoss</a></li>
<li>abc.ABC</li>
<li>torch.nn.modules.module.Module</li>
</ul>
<h3>Class variables</h3>
<dl>
<dt id="fusion.criterion.loss.VolumetricMultiDim.dump_patches"><code class="name">var <span class="ident">dump_patches</span> :Â bool</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="fusion.criterion.loss.VolumetricMultiDim.training"><code class="name">var <span class="ident">training</span> :Â bool</code></dt>
<dd>
<div class="desc"></div>
</dd>
</dl>
<h3>Inherited members</h3>
<ul class="hlist">
<li><code><b><a title="fusion.criterion.loss.multi_dim.MultiDim" href="multi_dim.html#fusion.criterion.loss.multi_dim.MultiDim">MultiDim</a></b></code>:
<ul class="hlist">
<li><code><a title="fusion.criterion.loss.multi_dim.MultiDim.forward" href="abaseloss.html#fusion.criterion.loss.abaseloss.ABaseLoss.forward">forward</a></code></li>
</ul>
</li>
</ul>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="fusion.criterion" href="../index.html">fusion.criterion</a></code></li>
</ul>
</li>
<li><h3><a href="#header-submodules">Sub-modules</a></h3>
<ul>
<li><code><a title="fusion.criterion.loss.abaseloss" href="abaseloss.html">fusion.criterion.loss.abaseloss</a></code></li>
<li><code><a title="fusion.criterion.loss.ae" href="ae.html">fusion.criterion.loss.ae</a></code></li>
<li><code><a title="fusion.criterion.loss.cr_cca" href="cr_cca.html">fusion.criterion.loss.cr_cca</a></code></li>
<li><code><a title="fusion.criterion.loss.dccae" href="dccae.html">fusion.criterion.loss.dccae</a></code></li>
<li><code><a title="fusion.criterion.loss.dim" href="dim/index.html">fusion.criterion.loss.dim</a></code></li>
<li><code><a title="fusion.criterion.loss.multi_dim" href="multi_dim.html">fusion.criterion.loss.multi_dim</a></code></li>
<li><code><a title="fusion.criterion.loss.pytorch_wrappers" href="pytorch_wrappers.html">fusion.criterion.loss.pytorch_wrappers</a></code></li>
<li><code><a title="fusion.criterion.loss.rr_ae" href="rr_ae.html">fusion.criterion.loss.rr_ae</a></code></li>
<li><code><a title="fusion.criterion.loss.tests" href="tests/index.html">fusion.criterion.loss.tests</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="fusion.criterion.loss.ABaseLoss" href="#fusion.criterion.loss.ABaseLoss">ABaseLoss</a></code></h4>
<ul class="">
<li><code><a title="fusion.criterion.loss.ABaseLoss.dump_patches" href="#fusion.criterion.loss.ABaseLoss.dump_patches">dump_patches</a></code></li>
<li><code><a title="fusion.criterion.loss.ABaseLoss.forward" href="#fusion.criterion.loss.ABaseLoss.forward">forward</a></code></li>
<li><code><a title="fusion.criterion.loss.ABaseLoss.training" href="#fusion.criterion.loss.ABaseLoss.training">training</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="fusion.criterion.loss.AE" href="#fusion.criterion.loss.AE">AE</a></code></h4>
<ul class="">
<li><code><a title="fusion.criterion.loss.AE.dump_patches" href="#fusion.criterion.loss.AE.dump_patches">dump_patches</a></code></li>
<li><code><a title="fusion.criterion.loss.AE.forward" href="#fusion.criterion.loss.AE.forward">forward</a></code></li>
<li><code><a title="fusion.criterion.loss.AE.training" href="#fusion.criterion.loss.AE.training">training</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="fusion.criterion.loss.BCEWithLogitsLoss" href="#fusion.criterion.loss.BCEWithLogitsLoss">BCEWithLogitsLoss</a></code></h4>
<ul class="">
<li><code><a title="fusion.criterion.loss.BCEWithLogitsLoss.dump_patches" href="#fusion.criterion.loss.BCEWithLogitsLoss.dump_patches">dump_patches</a></code></li>
<li><code><a title="fusion.criterion.loss.BCEWithLogitsLoss.forward" href="#fusion.criterion.loss.BCEWithLogitsLoss.forward">forward</a></code></li>
<li><code><a title="fusion.criterion.loss.BCEWithLogitsLoss.training" href="#fusion.criterion.loss.BCEWithLogitsLoss.training">training</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="fusion.criterion.loss.CR_CCA" href="#fusion.criterion.loss.CR_CCA">CR_CCA</a></code></h4>
<ul class="">
<li><code><a title="fusion.criterion.loss.CR_CCA.dump_patches" href="#fusion.criterion.loss.CR_CCA.dump_patches">dump_patches</a></code></li>
<li><code><a title="fusion.criterion.loss.CR_CCA.forward" href="#fusion.criterion.loss.CR_CCA.forward">forward</a></code></li>
<li><code><a title="fusion.criterion.loss.CR_CCA.training" href="#fusion.criterion.loss.CR_CCA.training">training</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="fusion.criterion.loss.CustomCrossEntropyLoss" href="#fusion.criterion.loss.CustomCrossEntropyLoss">CustomCrossEntropyLoss</a></code></h4>
<ul class="">
<li><code><a title="fusion.criterion.loss.CustomCrossEntropyLoss.dump_patches" href="#fusion.criterion.loss.CustomCrossEntropyLoss.dump_patches">dump_patches</a></code></li>
<li><code><a title="fusion.criterion.loss.CustomCrossEntropyLoss.forward" href="#fusion.criterion.loss.CustomCrossEntropyLoss.forward">forward</a></code></li>
<li><code><a title="fusion.criterion.loss.CustomCrossEntropyLoss.training" href="#fusion.criterion.loss.CustomCrossEntropyLoss.training">training</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="fusion.criterion.loss.DCCAE" href="#fusion.criterion.loss.DCCAE">DCCAE</a></code></h4>
<ul class="">
<li><code><a title="fusion.criterion.loss.DCCAE.dump_patches" href="#fusion.criterion.loss.DCCAE.dump_patches">dump_patches</a></code></li>
<li><code><a title="fusion.criterion.loss.DCCAE.forward" href="#fusion.criterion.loss.DCCAE.forward">forward</a></code></li>
<li><code><a title="fusion.criterion.loss.DCCAE.training" href="#fusion.criterion.loss.DCCAE.training">training</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="fusion.criterion.loss.RR_AE" href="#fusion.criterion.loss.RR_AE">RR_AE</a></code></h4>
<ul class="">
<li><code><a title="fusion.criterion.loss.RR_AE.dump_patches" href="#fusion.criterion.loss.RR_AE.dump_patches">dump_patches</a></code></li>
<li><code><a title="fusion.criterion.loss.RR_AE.forward" href="#fusion.criterion.loss.RR_AE.forward">forward</a></code></li>
<li><code><a title="fusion.criterion.loss.RR_AE.training" href="#fusion.criterion.loss.RR_AE.training">training</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="fusion.criterion.loss.SpatialMultiDim" href="#fusion.criterion.loss.SpatialMultiDim">SpatialMultiDim</a></code></h4>
<ul class="">
<li><code><a title="fusion.criterion.loss.SpatialMultiDim.dump_patches" href="#fusion.criterion.loss.SpatialMultiDim.dump_patches">dump_patches</a></code></li>
<li><code><a title="fusion.criterion.loss.SpatialMultiDim.training" href="#fusion.criterion.loss.SpatialMultiDim.training">training</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="fusion.criterion.loss.VolumetricMultiDim" href="#fusion.criterion.loss.VolumetricMultiDim">VolumetricMultiDim</a></code></h4>
<ul class="">
<li><code><a title="fusion.criterion.loss.VolumetricMultiDim.dump_patches" href="#fusion.criterion.loss.VolumetricMultiDim.dump_patches">dump_patches</a></code></li>
<li><code><a title="fusion.criterion.loss.VolumetricMultiDim.training" href="#fusion.criterion.loss.VolumetricMultiDim.training">training</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc"><cite>pdoc</cite> 0.9.2</a>.</p>
</footer>
</body>
</html>